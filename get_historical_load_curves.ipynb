{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de780a8d",
   "metadata": {},
   "source": [
    "# Intégration courbe de charge historique dans la bdd postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2764a34",
   "metadata": {},
   "source": [
    "### récupération des données de puis l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from app.api_client import get_consumption_load\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Charge les variables depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Récupérer le token\n",
    "API_TOKEN = os.getenv(\"API_TOKEN\")\n",
    "PRM = os.getenv(\"PRM\")\n",
    "\n",
    "\n",
    "\n",
    "start_date = \"2024-12-01\"\n",
    "\n",
    "start_date_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date_dt   = start_date_dt + timedelta(days=7)\n",
    "end_date = end_date_dt.strftime(\"%Y-%m-%d\")\n",
    "list_df_data = list()\n",
    "\n",
    "while end_date_dt <= datetime.now() + timedelta(days=1):\n",
    "    print(f\"Récupération des données du {start_date} au {end_date}\")\n",
    "    data = get_consumption_load(PRM, start_date, end_date, API_TOKEN)\n",
    "    start_date_dt = end_date_dt\n",
    "    start_date = start_date_dt.strftime(\"%Y-%m-%d\")\n",
    "    end_date_dt   = start_date_dt + timedelta(days=7)\n",
    "    end_date = end_date_dt.strftime(\"%Y-%m-%d\")\n",
    "    list_data = data['interval_reading']\n",
    "    df = pd.DataFrame(list_data)\n",
    "    list_df_data.append(df)\n",
    "\n",
    "last_date = datetime.strptime(data['interval_reading'][-1]['date'], \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "if last_date < datetime.now():\n",
    "    start_date = last_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_dt   = last_date + timedelta(days=1)\n",
    "    end_date = end_date_dt.strftime(\"%Y-%m-%d\")\n",
    "    data = get_consumption_load(PRM, start_date, end_date, API_TOKEN)\n",
    "    list_data = data['interval_reading']\n",
    "    df = pd.DataFrame(list_data)\n",
    "    list_df_data.append(df)\n",
    "\n",
    "\n",
    "dataconso = pd.concat(list_df_data, ignore_index=True)\n",
    "\n",
    "# Convertir la colonne 'date' en datetime\n",
    "dataconso['date'] = pd.to_datetime(dataconso['date'])\n",
    "\n",
    "# Convertir 'value' en numérique (int ou float)\n",
    "dataconso['value'] = pd.to_numeric(dataconso['value'])\n",
    "\n",
    "# Définir l'index temporel\n",
    "dataconso.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea29e36",
   "metadata": {},
   "source": [
    "### intégration des données dans la bdd postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Connexion à PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"electricite\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Labrax_007\"\n",
    ")\n",
    "\n",
    "# Créer un curseur\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Créer une table de test\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS courbecharge (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    timestamp TIMESTAMP,\n",
    "    value FLOAT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit() \n",
    "\n",
    "\n",
    "\n",
    "# Vérifie et convertis l'index si nécessaire\n",
    "print(\"Type de l'index avant conversion :\", type(dataconso.index))\n",
    "dataconso.index = pd.to_datetime(dataconso.index)  # Force la conversion en DatetimeIndex\n",
    "print(\"Type de l'index après conversion :\", type(dataconso.index))\n",
    "\n",
    "# Insertion des données\n",
    "for index, row in dataconso.iterrows():\n",
    "    try:\n",
    "        cur.execute(\n",
    "            sql.SQL(\"INSERT INTO courbecharge (timestamp, value) VALUES (%s, %s)\"),\n",
    "            (index, row['value'])\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur à l'insertion de la ligne {index}: {e}\")\n",
    "        conn.rollback()\n",
    "    else:\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f75e2",
   "metadata": {},
   "source": [
    "# Intégration des données journalières"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a7bf0",
   "metadata": {},
   "source": [
    "## Récupération des données depuis le Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7efce90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture des données du 2021-12-22 to 2024-12-04\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "dir_drive = \"G:\\Mon Drive\\Consommation logement\\données élec\\jour\"\n",
    "\n",
    "file_1 = \"enedis.xlsx\"\n",
    "df_histo1 = pd.read_excel(os.path.join(dir_drive, file_1))\n",
    "#df_histo1['Horodate'] = pd.to_datetime(df_histo1['Horodate'])\n",
    "df_histo1['consohp'] = df_histo1['EAS F1'].shift(-1) - df_histo1['EAS F1']\n",
    "df_histo1['consohc'] = df_histo1['EAS F2'].shift(-1) - df_histo1['EAS F2'] \n",
    "df_histo1['conso_kwh'] = (df_histo1['consohp']+df_histo1['consohc'])/1000.0\n",
    "df_histo1['jour'] = df_histo1['Horodate'].apply(lambda x: pd.to_datetime(x[0:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7162dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_histo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dec7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Chemin du répertoire (remplace par ton chemin)\n",
    "dir_drive = \"G:/Mon Drive/Consommation logement/données élec/jour/\"\n",
    "\n",
    "# Liste tous les fichiers Excel commençant par \"ch1\"\n",
    "fichiers_excel = glob.glob(f\"{dir_drive}02297250326360*.xlsx*\")\n",
    "\n",
    "list_df_data = list()\n",
    "# Affiche les fichiers trouvés\n",
    "for fichier in fichiers_excel:\n",
    "    print(fichier)\n",
    "    df_partielle = pd.read_excel(fichier, skiprows=13,sheet_name='Export Consommation Quotidienne', usecols=\"B,C\")\n",
    "    list_df_data.append(df_partielle)   \n",
    "\n",
    "df_histo2 = pd.concat(list_df_data, ignore_index=True)\n",
    "df_histo2['jour'] = pd.to_datetime(df_histo2['Date'], format=\"%d/%m/%Y\")\n",
    "\n",
    "df_histo2.sort_values(by='jour', inplace=True)  \n",
    "\n",
    "df_histo2.columns = ['Date', 'conso_kwh', 'jour']\n",
    "df_conso_histo = pd.concat([df_histo1[['conso_kwh', 'jour']], df_histo2[['conso_kwh', 'jour']]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
